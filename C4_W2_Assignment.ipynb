{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7yuytuIllsv1"
   },
   "source": [
    "\n",
    "# Assignment 2: Transformer Summarizer\n",
    "\n",
    "Welcome to the second assignment of course 4. In this assignment you will explore summarization using the transformer model. Yes, you will implement the transformer decoder from scratch, but we will slowly walk you through it. There are many hints in this notebook so feel free to use them as needed. \n",
    "\n",
    "<img src = \"images/transformerNews.png\">\n",
    "\n",
    "## Important Note on Submission to the AutoGrader\n",
    "\n",
    "Before submitting your assignment to the AutoGrader, please make sure you are not doing the following:\n",
    "\n",
    "1. You have not added any _extra_ `print` statement(s) in the assignment.\n",
    "2. You have not added any _extra_ code cell(s) in the assignment.\n",
    "3. You have not changed any of the function parameters.\n",
    "4. You are not using any global variables inside your graded exercises. Unless specifically instructed to do so, please refrain from it and use the local variables instead.\n",
    "5. You are not changing the assignment code where it is not required, like creating _extra_ variables.\n",
    "\n",
    "If you do any of the following, you will get something like, `Grader Error: Grader feedback not found` (or similarly unexpected) error upon submitting your assignment. Before asking for help/debugging the errors in your assignment, check for these first. If this is the case, and you don't remember the changes you have made, you can get a fresh copy of the assignment by following these [instructions](https://www.coursera.org/learn/attention-models-in-nlp/supplement/shBOS/how-to-refresh-your-workspace)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4-3lxSnXRWPx"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Introduction](#0)\n",
    "- [1 - Importing the Dataset](#1)\n",
    "    - [1.1 - Tokenize & Detokenize Helper Functions](#1-1)\n",
    "    - [1.2 - Preprocessing for Language Models: Concatenate It!](#1-2)\n",
    "    - [1.3 - Batching with Bucketing](#1-3)\n",
    "- [2 - Summarization with Transformer](#2)\n",
    "    - [2.1 - Dot Product Attention ](#2-1)\n",
    "        - [Exercise 1 - DotProductAttention (UNQ_C1)](#ex-1)\n",
    "    - [2.2 - Causal Attention](#2-2)\n",
    "        - [Exercise 2 - Causal Attention ](#ex-2)\n",
    "            - [Exercise 2a - compute_attention_heads (UNQ_C2)](#ex-2a)\n",
    "            - [Exercise 2b - dot_product_self_attention(UNQ_C3)](#ex-2b)\n",
    "            - [Exercise 2c - compute_attention_output (UNQ_C4)](#ex-2c)\n",
    "            - [Exercise 2d - CausalAttention (UNQ_C5)](#ex-2d)\n",
    "    - [2.3 - Transformer Decoder Block](#2-3)\n",
    "        - [Exercise 3 - DecoderBlock (UNQ_C6)](#ex-3)\n",
    "    - [2.4 - Transformer Language Model](#2-4)\n",
    "        - [Exercise 4 - TransformerLM (UNQ_C7)](#ex-4)\n",
    "- [3 - Training](#3)\n",
    "    - [3.1 - Training the Model](#3-1)\n",
    "        - [Exercise 5 - training_loop (UNQ_C8)](#ex-5)\n",
    "- [4 - Evaluation](#4)\n",
    "    - [4.1 - Loading in a Trained Model](#4-1)\n",
    "- [5 - Testing with your Own Input](#5) \n",
    "    - [Exercise 6 - next_symbol (UNQ_C9)](#ex-6)\n",
    "    - [5.1 - Greedy Decoding](#5-1)\n",
    "        - [Exercise 7 - greedy_decode (UNQ_C10)](#ex-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H4NlfEQhRWPy"
   },
   "source": [
    "<a name='0'></a>\n",
    "## Introduction\n",
    "\n",
    "Summarization is an important task in natural language processing and could be useful for a consumer enterprise. For example, bots can be used to scrape articles, summarize them, and then you can use sentiment analysis to identify the sentiment about certain stocks. Anyways who wants to read an article or a long email today, when you can build a transformer to summarize text for you. Let's get started, by completing this assignment you will learn to:  \n",
    "\n",
    "- Use built-in functions to preprocess your data\n",
    "- Implement DotProductAttention\n",
    "- Implement Causal Attention\n",
    "- Understand how attention works\n",
    "- Build the transformer model\n",
    "- Evaluate your model\n",
    "- Summarize an article\n",
    "\n",
    "As you can tell, this model is slightly different than the ones you have already implemented. This is heavily based on attention and does not rely on sequences, which allows for parallel computing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CChWzW-rEHVb",
    "outputId": "a0b3e98b-7fc6-492d-c8ad-3a263b54f670"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import w2_tests\n",
    "import numpy as np\n",
    "\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.fastmath import numpy as jnp\n",
    "\n",
    "# to print the entire np array\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kEL2rvaHRWP4"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Importing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trax makes it easy to work with Tensorflow's datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VInmKSkhEhle"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function TFDS.<locals>.select_from at 0x7f34b85e8440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function TFDS.<locals>.select_from at 0x7f34b85e8440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function TFDS.<locals>.select_from at 0x7f34b85e8440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDS.<locals>.select_from at 0x7f34b85e39e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function TFDS.<locals>.select_from at 0x7f34b85e39e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function TFDS.<locals>.select_from at 0x7f34b85e39e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# This will download the dataset if no data_dir is specified.\n",
    "# Downloading and processing can take bit of time,\n",
    "# so we have the data already in 'data/' for you\n",
    "\n",
    "# Importing CNN/DailyMail articles dataset\n",
    "train_stream_fn = trax.data.TFDS('cnn_dailymail',\n",
    "                                 data_dir='data/',\n",
    "                                 keys=('article', 'highlights'),\n",
    "                                 train=True)\n",
    "\n",
    "# This should be much faster as the data is downloaded already.\n",
    "eval_stream_fn = trax.data.TFDS('cnn_dailymail',\n",
    "                                data_dir='data/',\n",
    "                                keys=('article', 'highlights'),\n",
    "                                train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-1'></a>\n",
    "## 1.1 - Tokenize & Detokenize Helper Functions\n",
    "\n",
    "Just like in the previous assignment, the cell above loads in the encoder for you. Given any data set, you have to be able to map words to their indices, and indices to their words. The inputs and outputs to your [Trax](https://github.com/google/trax) models are usually tensors of numbers where each number corresponds to a word. If you were to process your data manually, you would have to make use of the following: \n",
    "\n",
    "- <span style='color:blue'> word2Ind: </span> a dictionary mapping the word to its index.\n",
    "- <span style='color:blue'> ind2Word:</span> a dictionary mapping the index to its word.\n",
    "- <span style='color:blue'> word2Count:</span> a dictionary mapping the word to the number of times it appears. \n",
    "- <span style='color:blue'> num_words:</span> total number of words that have appeared. \n",
    "\n",
    "Since you have already implemented these in previous assignments of the specialization, we will provide you with helper functions that will do this for you. Run the cell below to get the following functions:\n",
    "\n",
    "- <span style='color:blue'> tokenize: </span> converts a text sentence to its corresponding token list (i.e. list of indices). Also converts words to subwords.\n",
    "- <span style='color:blue'> detokenize: </span> converts a token list to its corresponding sentence (i.e. string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djTiSLcaNFGa"
   },
   "outputs": [],
   "source": [
    "def tokenize(input_str, EOS=1):\n",
    "    \"\"\"Input str to features dict, ready for inference\"\"\"\n",
    "  \n",
    "    # Use the trax.data.tokenize method. It takes streams and returns streams,\n",
    "    # we get around it by making a 1-element stream with `iter`.\n",
    "    inputs =  next(trax.data.tokenize(iter([input_str]),\n",
    "                                      vocab_dir='vocab_dir/',\n",
    "                                      vocab_file='summarize32k.subword.subwords'))\n",
    "    \n",
    "    # Mark the end of the sentence with EOS\n",
    "    return list(inputs) + [EOS]\n",
    "\n",
    "def detokenize(integers):\n",
    "    \"\"\"List of ints to str\"\"\"\n",
    "  \n",
    "    s = trax.data.detokenize(integers,\n",
    "                             vocab_dir='vocab_dir/',\n",
    "                             vocab_file='summarize32k.subword.subwords')\n",
    "    \n",
    "    return wrapper.fill(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7WvhaFbCRWQS"
   },
   "source": [
    "<a name='1-2'></a>\n",
    "## 1.2 - Preprocessing for Language Models: Concatenate It!\n",
    "\n",
    "This week you will use a language model -- Transformer Decoder -- to solve\n",
    "an input-output problem. As you know, language models only predict the next\n",
    "word, they have no notion of inputs. To create a single input suitable for\n",
    "a language model, we concatenate inputs with targets putting a separator\n",
    "in between. We also need to create a mask -- with 0s at inputs and 1s at targets -- so that the model is not penalized for mis-predicting the article and only focuses on the summary. See the preprocess function below for how this is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4rgPxYSRWQS"
   },
   "outputs": [],
   "source": [
    "# Special tokens\n",
    "SEP = 0 # Padding or separator token\n",
    "EOS = 1 # End of sentence token\n",
    "\n",
    "# Concatenate tokenized inputs and targets using 0 as separator.\n",
    "def preprocess(stream):\n",
    "    for (article, summary) in stream:\n",
    "        joint = np.array(list(article) + [EOS, SEP] + list(summary) + [EOS])\n",
    "        mask = [0] * (len(list(article)) + 2) + [1] * (len(list(summary)) + 1) # Accounting for EOS and SEP\n",
    "        yield joint, joint, np.array(mask)\n",
    "\n",
    "# You can combine a few data preprocessing steps into a pipeline like this.\n",
    "input_pipeline = trax.data.Serial(\n",
    "    # Tokenizes\n",
    "    trax.data.Tokenize(vocab_dir='vocab_dir/',\n",
    "                       vocab_file='summarize32k.subword.subwords'),\n",
    "    # Uses function defined above\n",
    "    preprocess,\n",
    "    # Filters out examples longer than 2048\n",
    "    trax.data.FilterByLength(2048)\n",
    ")\n",
    "\n",
    "# Apply preprocessing to data streams.\n",
    "train_stream = input_pipeline(train_stream_fn())\n",
    "eval_stream = input_pipeline(eval_stream_fn())\n",
    "\n",
    "train_input, train_target, train_mask = next(train_stream)\n",
    "\n",
    "assert sum((train_input - train_target)**2) == 0  # They are the same in Language Model (LM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "uKFoGsUKSa_I",
    "outputId": "bc4d6634-d716-4311-d49c-1956bca2bc2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single example mask:\n",
      "\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# prints mask, 0s on article, 1s on summary\n",
    "print(f'Single example mask:\\n\\n {train_mask}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "S4uHyCkbSuUo",
    "outputId": "52845be8-f2fc-4803-bf7a-ed9725fe2bac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single example:\n",
      "\n",
      " Gordon Brown gave Labour rising star Chuka Umunna ‘the hairdryer\n",
      "treatment’ in a blistering phone call after the shadow business\n",
      "secretary publicly blamed him for Labour’s struggles on the economy.\n",
      "Mr Brown attacked the shadow cabinet minister for an interview he gave\n",
      "criticising the former Labour leader’s failure to confront Britain’s\n",
      "ballooning deficit in the run up to the 2010 election. Mr Umunna said\n",
      "Mr Brown’s refusal to even talk about Government ‘cuts’ was still\n",
      "costing Labour support, because it made the party look like it did not\n",
      "care about the deficit. Labour are currently 25 points behind the\n",
      "Tories on which party is best for the economy. Scroll down for video .\n",
      "Shadow business secretary Chuka Umunna (left) and Gordon Brown (right)\n",
      "clashed on the phone over Labour's record on the economy . But the\n",
      "remarks sparked a furious response from Mr Brown, MailOnline has\n",
      "learnt. The former Prime Minister told Mr Umunna that he should not\n",
      "accept Tory claims that Labour was spending too much before the last\n",
      "general election, a senior Labour source revealed. The source said:\n",
      "‘He still cannot accept Labour was running a structural deficit. Even\n",
      "after all this time he won’t accept that he was wrong – it’s\n",
      "unbelievable.’ The deficit – the difference between Government\n",
      "spending and how much it raises in taxes each year – was more than\n",
      "£160 billion in 2010. Labour blamed the huge borrowing splurge on the\n",
      "global recession – because the Government was forced to withstand a\n",
      "huge hit on tax revenue as people lost their jobs, while at the same\n",
      "time increasing spending on benefits. But analysis has since revealed\n",
      "that the ‘structural deficit’ – the amount of borrowing needed even\n",
      "when the economy is growing normally – had grown to more than £100\n",
      "billion in the last year of the Labour government. In an interview\n",
      "with GQ magazine, published this month, Mr Umunna said Mr Brown’s\n",
      "refusal to face up to the deficit was still hurting the Labour Party.\n",
      "He said: ‘My view is that the seeds were sown under the last\n",
      "government and Gordon - for whom I have a lot of respect - his refusal\n",
      "to use the word “cuts” in trying to frame the economic debate as\n",
      "investment versus cuts gave the impression we didn't understand that\n",
      "debt and deficit would have to be dealt with.’ Shadow chancellor Ed\n",
      "Balls (left) and the Labour leader Ed Miliband (right), who were both\n",
      "Treasury aides under Gordon Brown, have defended the party's record\n",
      "controlling Government spending . A source close to Mr Umunna\n",
      "confirmed the pair spoke in a telephone call after the interview was\n",
      "published earlier this month. The source said: ‘It is something they\n",
      "disagree on. ‘Chuka’s argument has always been that pursuing the line\n",
      "that it was Labour spending versus Tory cuts allowed Osborne to make\n",
      "the whole election debate about deficit reduction. They spoke and that\n",
      "is definitely still his view.’ A spokesman for Mr Umunna said: 'Chuka\n",
      "and Gordon are both members of the PLP - or course they speak to each\n",
      "other on a range of issues. Chuka has great respect for Gordon.' It is\n",
      "understood that on this occasion Mr Umunna initiated the call.\n",
      "Conservative MP Henry Smith said the confrontation between Mr Brown\n",
      "and Mr Umunna revealed a 'divided' Labour Party. He said: 'This shows\n",
      "a Labour party still in denial about the record deficit they left\n",
      "behind and with no plan to deal with our debts and ensure a more\n",
      "financially secure future for Britain. 'Brown’s intervention begs the\n",
      "question who’s in charge of a clearly split and infighting Labour\n",
      "leadership team.'<EOS><pad>EXCLUSIVE: Source reveals extraordinary\n",
      "call by ex Prime Minister . Mr Umunna blamed former PM for Labour's\n",
      "economic credibility problem . He said Mr Brown 'gave impression we\n",
      "didn't understand debt and deficit' Former Labour leader confronted Mr\n",
      "Umunna in an angry call afterwards .<EOS>\n"
     ]
    }
   ],
   "source": [
    "# prints: [Example][<EOS>][<pad>][Example Summary][<EOS>]\n",
    "print(f'Single example:\\n\\n {detokenize(train_input)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4sDS1WIVaYG"
   },
   "source": [
    "<a name='1-3'></a>\n",
    "## 1.3 - Batching with Bucketing\n",
    "\n",
    "As in the previous week, we use bucketing to create batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oqj1NsbERWQX"
   },
   "outputs": [],
   "source": [
    "# Bucketing to create batched generators.\n",
    "\n",
    "# Buckets are defined in terms of boundaries and batch sizes.\n",
    "# Batch_sizes[i] determines the batch size for items with length < boundaries[i]\n",
    "# So below, we'll take a batch of 16 sentences of length < 128 , 8 of length < 256,\n",
    "# 4 of length < 512. And so on. \n",
    "boundaries =  [128, 256,  512, 1024]\n",
    "batch_sizes = [16,    8,    4,    2, 1]\n",
    "\n",
    "# Create the streams.\n",
    "train_batch_stream = trax.data.BucketByLength(\n",
    "    boundaries, batch_sizes)(train_stream)\n",
    "\n",
    "eval_batch_stream = trax.data.BucketByLength(\n",
    "    boundaries, batch_sizes)(eval_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6M5OA8QRWQb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every execution will result in generation of a different article\n",
    "# Try running this cell multiple times to see how the length of the examples affects the batch size\n",
    "input_batch, _, mask_batch = next(train_batch_stream)\n",
    "\n",
    "# Shape of the input_batch\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SjNOlljxTGuQ",
    "outputId": "9227c68c-6369-4ce8-8137-506c594f6ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  567   379 13260  1619  3194 25474    47   379    27   459   968  3113\n",
      "  1353  1343   132 26549  7511    28 19326    16 13578 10811   330  1205\n",
      "    68   192  6040    28  1650   809   208  1869     3 21657  3371     2\n",
      "  1421     2   995   320 26549   320   126  1019   968   782   947  1909\n",
      "     6 25092 12752    28     2   186    40    46    64  1248  4771   171\n",
      "   144 19941   246   412   131  9227   213   826   809 22079    75     2\n",
      "   163  4889  7810  1613     3   305  1353   213   968   947     7     5\n",
      "    60  1361  2034  1108     2   186   995   320   213  1975   644  1019\n",
      "   126  1248    68  2136  1565  5436     2  1120     3 15685    21    11\n",
      " 21657  3371     2 12370    21     2  1353 19941   246   186  1343   691\n",
      "    28 13578 10811   330   132 26549   132   420   379  2713  3640  2162\n",
      "  1678  3371     7     5   583  1353 14040     4    70    35   103   272\n",
      "  4686   285   213 13578  9195 20016     4    40    92  3156 17951     2\n",
      "   186  1353  6040    28  1650  7511    22  1205  1678  3371    78   508\n",
      "   247     2   420     3    27   541     6   104     6   292   157  1353\n",
      "  9733   527  4874 21657   132    28  6079  9282     4   924   132   420\n",
      "  1248    28  4038  8599    15  1869   412   117 13241  1099   514  4889\n",
      "  7810   132 25656  1323     2 17236     2  1613   285   213 25224    58\n",
      "  1205  1678  3371    70  1779    40   141 12843    64    71   213   826\n",
      "    70   192  1429   320   155     6   245    15  8772     3 10305  4097\n",
      "   102 19444    16    71   213   826   131  1353  5485   691   213 13578\n",
      " 10811   330   412    22  4986   320   155     6   245    15  1650     3\n",
      "  2349  3374   760     2  1678  3371     7     5  1037  5315     2  2910\n",
      "     2   897   213  1710   131   233    64  2685    68  1330 29725     4\n",
      "     5   583   412   117   213  4947  2067   922   527   130   177  1099\n",
      "   305   969  3611   861  8593  1330 21657    62  1151   265   592   122\n",
      "   285 16013   256     2  4398 13578 10811   330    40    19    46  6040\n",
      "  1248    28  1650   809 22079    75  1099   368  5436    43  1537  7687\n",
      "   320    15   532   938     2  1457    22    40  1042   141   711   171\n",
      "    68   583   132   163 25396     5     6 26610    21 10207 11164  4652\n",
      "  1782 10020 22488     4 15570     9 13578 10811   330  1353 15770    15\n",
      "  8772   132    28  1576  1239  7511    22  1205  1678  3371     3    27\n",
      "  6079  9282     4   924  9733   134   527   213  4874   379  1565     2\n",
      "  2179  1838  6041  7928  1532 17236     2   127  3611 21657  1353   163\n",
      "  3362   537     3   305  1353   855     2 10015     2    77   320   399\n",
      "   186   369    40    28  1519  1032   320   476  2685  1815  1782   129\n",
      "    25   517     6  6561  2948  1779 23671  5373   320   191    28   227\n",
      "   177   186   227  8886  1019  7238  1782    56  1353    38   576   463\n",
      "   691    28   157  1779  1353    64  6040    28 13578  9195  1248    15\n",
      "  1078  2002    27 25290 16741    20   648  1526    64   132 26549   233\n",
      "  3066  2471  3864   527  4016   318  4196 10187   132 21657 29725     4\n",
      "     5  1884     2   239   150     6   186     6    28     6   605   450\n",
      "   213   459  6700     6  2057  3602     3  2375   527  1678  3371     7\n",
      "     5  4771   793   213  3729   131   206    19  1500 23176    78   213\n",
      "   736   131   710     3 10736  6156   127  3611   129    40    28   335\n",
      " 15697    35  1290   407   412    51    25 10818   704   320   213  1026\n",
      "     3    52 29725     4     5    19   107    51    25 26831   959  6661\n",
      "   809   213  1942  1099   350 17236 19853    81  1983   873  9726   127\n",
      "  3611    52    40  1472   285   213 13578 10811   330  1353 15770    36\n",
      "   527    15 22434     4  7511   213 25725   436   219  2002  1975   644\n",
      "    11  1678  3371   995   320 26549  1019   126  1248    68  2136  1565\n",
      "  5436   379    69   969   285    77  1353 17679   760   320  1771    28\n",
      " 18572 12585   527 25528  4874     2  1382  2654   213  4287   412    28\n",
      "   583  1768   412    28   581   527    28   826  1794 25725     3    27\n",
      "  1650   527   213   228   127   592  3611     9   228  1435  5912 15605\n",
      "   285   213 19853    81  3528  3226    28 18572 12585   527 14040     4\n",
      "   583  1782    52   229   213   228 29725     4     5   586   285 21657\n",
      "  1353    19  1343   132   163  5556     3     9 13578 10811   330  1205\n",
      "    68   145   163  5351   826  1239  1782   223    22    40    19    46\n",
      "   892   160   132   163  5351   889 21657    62   234  1151   265   592\n",
      "  2002 21657   186    68  2136  1565   995   320 22659   551 13500  6662\n",
      "     2  7798     2   132   472  7511   131   345   213    60  1361  2034\n",
      "  1108   527   630   782   809  1909 25092 12752    28   461     3   207\n",
      "   146  4367   320 25558    28   132   560   421  7511 21657  1353  5125\n",
      "   320  1909 25092 12752    28   461 29725     4     5   570   797     3\n",
      " 17895   102   213  4889  7810     2    68  1037   127  3611   305  1353\n",
      "   106    28 19442 21541    93   537   186    90   444   527   177     3\n",
      " 12026    16  7270   506   131  1353   131    23   757    90   196   132\n",
      "    68   177  1782   312    51   533    64    77   186   980  2754   177\n",
      "  1353   107    51 16920  7270   749    28   537   131  1353     3   129\n",
      "  1435    38    90 12327  4225   527    68   186  2754   131   206  2002\n",
      "  7386 25366  3371     2    68  2571     2   969  3611   129    25    38\n",
      "   456   704     2   131  3115    68   228     3   305   206    44   132\n",
      "    68  1421    91    74    94   124   132    28  7439 11585     1     0\n",
      " 21657  3371     2  1421     2  1353  1343   239 22079    75    78   508\n",
      "   247     2   420 16346 27439  6774  1628   305  1353  1205   691 25224\n",
      "    58  1779  1353 15770    15  8772     2  4889  7810  1613 16346 27439\n",
      "  6774  1628  1678  3371   995   320 26549  1019   126     2   186    40\n",
      "  1042   141   711   171 16346 27439  6774  1628   305  1353   213    60\n",
      "   545  1361  2034  1108   809  1909     6 25092 12752    28   968   947\n",
      "  2104     1     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "# print corresponding integer values\n",
    "print(input_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GD-72TENV2Jk"
   },
   "source": [
    "Things to notice:\n",
    " - First we see the corresponding values of the words.\n",
    " - The first 1, which represents the `<EOS>` tag of the article.\n",
    " - Followed by a 0, which represents a `<pad>` tag.\n",
    " - After the first 0 (`<pad>` tag) the corresponding values are of the words that are used for the summary of the article.\n",
    " - The second 1 represents the `<EOS>` tag for the summary.\n",
    " - All the trailing 0s represent `<pad>` tags which are appended to maintain consistent length (If you don't see them then it would mean it is already of max length)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Bu05ZwbWTE6P",
    "outputId": "3d455bd7-e343-4c25-a467-572d2abd837f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:\n",
      "\n",
      " By . Kieran Corcoran . A British TV producer was killed in Qatar when\n",
      "a speeding motorcyclist hit her while racing a friend at high speed.\n",
      "Kerry Rome, 33, moved to Qatar to work for TV news station Al-Jazeera,\n",
      "and had been out with colleagues before being knocked down as she\n",
      "crossed the road at 2am, an inquest heard. She was the TV station's\n",
      "first female technical director, and moved to the Middle East for work\n",
      "with her husband Mark Harris, 35. Killed: Kerry Rome, pictured, was\n",
      "knocked down and killed by a motorcyclist in Qatar in 2012 . Police\n",
      "initially believed Mrs Rome's death was accidental - but it later\n",
      "emerged that the motorbike rider had no driving licence, and was\n",
      "racing a friend when he hit Mrs Rome on April 20, 2012. A 21-year-old\n",
      "man was convicted of killing Kerry in a Qatari court in 2012 with a\n",
      "judge describing his speed as 'excessive'. An inquest in Stamford,\n",
      "Lincolnshire, heard that the biker hit Mrs Rome - who had just stepped\n",
      "out into the road - while trying to under-take his rival. Moments\n",
      "after stepping into the road she was struck by the motorcyclist as he\n",
      "attempted to under-take his friend. Giving evidence, Mrs Rome's mother\n",
      "Margaret, 62, described the moment she found out about her daughter’s\n",
      "death as 'the worst phone call of my life'. She added: 'My lovely\n",
      "daughter Kerry would be here today if that reckless, dangerous\n",
      "motorcyclist had not been racing with a friend at 2am'. Mr Harris also\n",
      "paid tribute to his late wife, whom he had married just months before\n",
      "her death in an Elvis-themed Las Vegas wedding. 'Excessive': The\n",
      "motorcyclist was undertaking his rival in a street race when he hit\n",
      "Mrs Rome. A Qatari court convicted him of the killing . Mark,\n",
      "originally from Market Deeping Lincolnshire, said: 'Kerry was an\n",
      "amazing person. She was kind, generous, there to help and never had a\n",
      "bad word to say about anyone. 'We were career-oriented adults who\n",
      "relocated abroad to make a good life and good careers for ourselves.\n",
      "'This was all taken away by a man who was out racing a motorbike with\n",
      "his friends.' A toxicology report carried out in Qatar found 296mg of\n",
      "alcohol per 100ml in Kerry’s blood, around three-and-a-half times the\n",
      "British drink-drive limit. Three of Mrs Rome's colleagues told the\n",
      "hearing she did not appear drunk on the night she died. Oliver Walker\n",
      "said: 'We had a few drinks but nothing major as we were dancing close\n",
      "to the stage. It’s not like we were pounding shots at the bar'. South\n",
      "Lincolnshire coroner Professor Robert Forrest said: 'It had appeared\n",
      "that the motorcyclist was undertaking one of his companions when the\n",
      "collision took place.' Middle East: Mrs Rome moved to Qatar for work\n",
      "with her husband Mark Harris . He added that there was insufficient\n",
      "evidence to produce a verdict of unlawful killing, instead recording\n",
      "the incident as a death caused as a result of a road traffic\n",
      "collision. A friend of the family said today: 'The family are\n",
      "obviously disappointed that the coroner effectively delivered a\n",
      "verdict of accidental death. 'It is the family’s position that Kerry\n",
      "was not killed in an accident. The motorcyclist hit her during an\n",
      "illegal road race. 'If he had not been taking part in an illegal\n",
      "activity Kerry would still be here today.' Kerry and her husband Mark\n",
      "moved to Kuala Lumpur, Malaysia, in 2008 when she became the first\n",
      "female technical director of live news at Al Jazeera English. They\n",
      "then transferred to Doha in October 2011 when Kerry was promoted to Al\n",
      "Jazeera English’s head office. Speaking after the inquest, her mother\n",
      "said: 'She was such a vivacious person and so full of life.\n",
      "Considering how young she was she has done so much in her life. 'When\n",
      "we went out there and saw what life was like we realised how strong a\n",
      "person she was. We are all so incredibly proud of her and what she\n",
      "did.' Kirsty Rome, her sister, added: 'We were all really close, she\n",
      "loved her family. She did more in her 33 years than most do in a\n",
      "lifetime.'<EOS><pad>KerryRome, 33, was killed around 2am on April 20,\n",
      "2012 . She was hit by biker who was undertaking his rival, inquest\n",
      "heard . Mrs Rome moved to Qatar for work, and had married just months\n",
      "before . She was the first ever female technical director at Al-\n",
      "Jazeera TV station .<EOS><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "# print the article and its summary\n",
    "print('Article:\\n\\n', detokenize(input_batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNFVhgHoncGm"
   },
   "source": [
    "You can see that the data has the following structure:\n",
    "- <span style='color:blue'> [Article] </span> -> `<EOS>` -> `<pad>` -> <span style='color:blue'> [Article Summary] </span> -> `<EOS>` -> (possibly) multiple `<pad>`\n",
    "\n",
    "The loss is taken only on the summary using cross_entropy as loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Un8NHIRoj-1W"
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Summarization with Transformer\n",
    "\n",
    "Now that we have given you the data generator and have handled the preprocessing for you, it is time for you to build your own model. We saved you some time because we know you have already preprocessed data before in this specialization, so we would rather you spend your time doing the next steps. \n",
    "\n",
    "You will be implementing the attention from scratch and then using it in your transformer model. Concretely, you will understand how attention works, how you use it to connect the encoder and the decoder.\n",
    "\n",
    "<img src=\"images/transformer_decoder_zoomin.png\">\n",
    "\n",
    "<a name='2-1'></a>\n",
    "### 2.1 - Dot Product Attention \n",
    "\n",
    "Now you will implement dot product attention which takes in a query, key, value, and a mask. It returns the output. \n",
    "\n",
    "<img src =\"images/dotproduct.png\">\n",
    "\n",
    "\n",
    "Here are some helper functions that will help you create tensors and display useful information:\n",
    "   - `create_tensor`  creates a `jax numpy array` from a list of lists.\n",
    "   - `display_tensor` prints out the shape and the actual tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor(t):\n",
    "    \"\"\"Create tensor from list of lists\"\"\"\n",
    "    return jnp.array(t)\n",
    "\n",
    "\n",
    "def display_tensor(t, name):\n",
    "    \"\"\"Display shape and tensor\"\"\"\n",
    "    print(f'{name} shape: {t.shape}\\n')\n",
    "    print(f'{t}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing it yourself, you can play around with a toy example of `dot product attention` without the softmax  operation. Technically it would not be `dot product attention` without the softmax but this is done to avoid giving away too much of the answer and the idea is to display these tensors to give you a sense of how they look like.\n",
    "\n",
    "The formula for attention is this one:\n",
    "\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n",
    "$$\n",
    "\n",
    "$d_{k}$ stands for the dimension of queries and keys.\n",
    "\n",
    "The `query`, `key`, `value` and `mask` vectors are provided for this example.\n",
    "\n",
    "Notice that the masking is done using very negative values that will yield a similar effect to using $-\\infty $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "_0x0HJXwRWQk",
    "outputId": "d6d78a8e-e3cc-47af-9584-2bdcdfcca0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query shape: (2, 3)\n",
      "\n",
      "[[1 0 0]\n",
      " [0 1 0]]\n",
      "\n",
      "key shape: (2, 3)\n",
      "\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "value shape: (2, 3)\n",
      "\n",
      "[[0 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "mask shape: (2, 2)\n",
      "\n",
      "[[ 0.e+00 -1.e+09]\n",
      " [ 0.e+00  0.e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = create_tensor([[1, 0, 0], [0, 1, 0]])\n",
    "display_tensor(q, 'query')\n",
    "k = create_tensor([[1, 2, 3], [4, 5, 6]])\n",
    "display_tensor(k, 'key')\n",
    "v = create_tensor([[0, 1, 0], [1, 0, 1]])\n",
    "display_tensor(v, 'value')\n",
    "m = create_tensor([[0, -1e9], [0, 0]])\n",
    "display_tensor(m, 'mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "query shape: (2, 3)\n",
    "\n",
    "[[1 0 0]\n",
    " [0 1 0]]\n",
    "\n",
    "key shape: (2, 3)\n",
    "\n",
    "[[1 2 3]\n",
    " [4 5 6]]\n",
    "\n",
    "value shape: (2, 3)\n",
    "\n",
    "[[0 1 0]\n",
    " [1 0 1]]\n",
    "\n",
    "mask shape: (2, 2)\n",
    "\n",
    "[[ 0.e+00 -1.e+09]\n",
    " [ 0.e+00  0.e+00]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kVR9u4faRWQo",
    "outputId": "f01ea4ca-4152-4b54-b76a-e4b5917ae2b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query dot key shape: (2, 2)\n",
      "\n",
      "[[0.57735026 2.309401  ]\n",
      " [1.1547005  2.8867514 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_dot_k = q @ k.T / jnp.sqrt(3)\n",
    "display_tensor(q_dot_k, 'query dot key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "query dot key shape: (2, 2)\n",
    "\n",
    "[[0.57735026 2.309401  ]\n",
    " [1.1547005  2.8867514 ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked query dot key shape: (2, 2)\n",
      "\n",
      "[[ 5.7735026e-01 -1.0000000e+09]\n",
      " [ 1.1547005e+00  2.8867514e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "masked = q_dot_k + m\n",
    "display_tensor(masked, 'masked query dot key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "masked query dot key shape: (2, 2)\n",
    "\n",
    "[[ 5.7735026e-01 -1.0000000e+09]\n",
    " [ 1.1547005e+00  2.8867514e+00]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked query dot key dot value shape: (2, 3)\n",
      "\n",
      "[[-1.0000000e+09  5.7735026e-01 -1.0000000e+09]\n",
      " [ 2.8867514e+00  1.1547005e+00  2.8867514e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_tensor(masked @ v, 'masked query dot key dot value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "masked query dot key dot value shape: (2, 3)\n",
    "\n",
    "[[-1.0000000e+09  5.7735026e-01 -1.0000000e+09]\n",
    " [ 2.8867514e+00  1.1547005e+00  2.8867514e+00]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the previous dummy tensors to test some of the graded functions, a batch dimension should be added to them so they mimic the shape of real-life examples. The mask is also replaced by a version of it that resembles the one that is used by trax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[1 0 0]\n",
      "  [0 1 0]]]\n",
      "\n",
      "key with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[1 2 3]\n",
      "  [4 5 6]]]\n",
      "\n",
      "value with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[0 1 0]\n",
      "  [1 0 1]]]\n",
      "\n",
      "boolean mask shape: (2, 2)\n",
      "\n",
      "[[ True False]\n",
      " [ True  True]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_with_batch = q[None,:]\n",
    "display_tensor(q_with_batch, 'query with batch dim')\n",
    "k_with_batch = k[None,:]\n",
    "display_tensor(k_with_batch, 'key with batch dim')\n",
    "v_with_batch = v[None,:]\n",
    "display_tensor(v_with_batch, 'value with batch dim')\n",
    "m_bool = create_tensor([[True, False], [True, True]])\n",
    "display_tensor(m_bool, 'boolean mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "query with batch dim shape: (1, 2, 3)\n",
    "\n",
    "[[[1 0 0]\n",
    "  [0 1 0]]]\n",
    "\n",
    "key with batch dim shape: (1, 2, 3)\n",
    "\n",
    "[[[1 2 3]\n",
    "  [4 5 6]]]\n",
    "\n",
    "value with batch dim shape: (1, 2, 3)\n",
    "\n",
    "[[[0 1 0]\n",
    "  [1 0 1]]]\n",
    "\n",
    "boolean mask shape: (2, 2)\n",
    "\n",
    "[[ True False]\n",
    " [ True  True]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - DotProductAttention\n",
    "\n",
    "**Instructions:** Implement the dot product attention. Concretely, implement the following equation\n",
    "\n",
    "\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n",
    "$$\n",
    "\n",
    "$Q$ - query, \n",
    "$K$ - key, \n",
    "$V$ - values, \n",
    "$M$ - mask, \n",
    "${d_k}$ - depth/dimension of the queries and keys (used for scaling down)\n",
    "\n",
    "You can implement this formula either by `trax` numpy (trax.math.numpy) or regular `numpy` but it is recommended to use `jnp`.\n",
    "\n",
    "Something to take into consideration is that within trax, the masks are tensors of `True/False` values not 0's and $-\\infty$ as in the previous example. Within the graded function don't think of applying the mask by summing up matrices, instead use `jnp.where()` and treat the **mask as a tensor of boolean values with `False` for values that need to be masked and True for the ones that don't.**\n",
    "\n",
    "Also take into account that the real tensors are far more complex than the toy ones you just played with. Because of this avoid using shortened operations such as `@` for dot product or `.T` for transposing. Use `jnp.matmul()` and `jnp.swapaxes()` instead.\n",
    "\n",
    "This is the self-attention block for the transformer decoder. Good luck!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSauPt0NUl_o"
   },
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: DotProductAttention\n",
    "def DotProductAttention(query, key, value, mask):\n",
    "    \"\"\"Dot product self-attention.\n",
    "    Args:\n",
    "        query (jax.interpreters.xla.DeviceArray): array of query representations with shape (L_q by d)\n",
    "        key (jax.interpreters.xla.DeviceArray): array of key representations with shape (L_k by d)\n",
    "        value (jax.interpreters.xla.DeviceArray): array of value representations with shape (L_k by d) where L_v = L_k\n",
    "        mask (jax.interpreters.xla.DeviceArray): attention-mask, gates attention with shape (L_q by L_k)\n",
    "\n",
    "    Returns:\n",
    "        jax.interpreters.xla.DeviceArray: Self-attention array for q, k, v arrays. (L_q by d)\n",
    "    \"\"\"\n",
    "\n",
    "    assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"Embedding dimensions of q, k, v aren't all the same\"\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
    "    # Save depth/dimension of the query embedding for scaling down the dot product\n",
    "    depth = query.shape[-1]\n",
    "\n",
    "    # Calculate scaled query key dot product according to formula above\n",
    "    dots = jnp.matmul(query, jnp.swapaxes(key, -1, -2)) / jnp.sqrt(depth)\n",
    "    \n",
    "    # Apply the mask\n",
    "    if mask is not None: # You do not need to replace the 'None' on this line\n",
    "        dots = jnp.where(mask, dots, jnp.full_like(dots, -1e9))\n",
    "    \n",
    "    # Softmax formula implementation\n",
    "    # Use trax.fastmath.logsumexp of masked_qkT to avoid underflow by division by large numbers\n",
    "    # Note: softmax = None\n",
    "    logsumexp = trax.fastmath.logsumexp(dots, axis=-1, keepdims=True)\n",
    "\n",
    "    # Take exponential of dots minus logsumexp to get softmax\n",
    "    # Use jnp.exp()\n",
    "    dots = jnp.exp(dots - logsumexp)\n",
    "\n",
    "    # Multiply dots by value to get self-attention\n",
    "    # Use jnp.matmul()\n",
    "    attention = jnp.matmul(dots, value)\n",
    "\n",
    "    ## END CODE HERE ###\n",
    "    \n",
    "    return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8o0K7VWKRWQw",
    "outputId": "1c51af3a-5f11-480f-b33b-419072d8298c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[0.        , 1.        , 0.        ],\n",
       "              [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DotProductAttention(q_with_batch, k_with_batch, v_with_batch, m_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "DeviceArray([[[0.        , 1.        , 0.        ],\n",
    "              [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "# test DotProductAttention\n",
    "w2_tests.test_DotProductAttention(DotProductAttention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2y2PSiLVRWQ2"
   },
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 - Causal Attention\n",
    "\n",
    "Now you are going to implement causal attention: multi-headed attention with a mask to attend only to words that occurred before. \n",
    "\n",
    "<img src = \"images/causal.png\">\n",
    "\n",
    "In the image above, a word can see everything that is before it, but not what is after it. To implement causal attention, you will have to transform vectors and do many reshapes. You will need to implement the functions below.\n",
    "\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Exercise 2 - Causal Attention\n",
    "\n",
    "Implement the following functions that will be needed for Causal Attention:\n",
    "\n",
    "- <span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (n_batch, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (n_batch $\\times$ n_heads, seqlen, d_head).\n",
    "- <span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention.\n",
    "- <span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (n_batch, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. \n",
    "\n",
    "Next there are some toy tensors which may serve to give you an idea of the data shapes and opperations involved in Causal Attention. They are also useful to test out your functions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "VRH67YcrRWQ3",
    "outputId": "847a9416-877a-4246-c738-0eacdf46de59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query matrix (2D tensor) shape: (2, 3)\n",
      "\n",
      "[[1 0 0]\n",
      " [0 1 0]]\n",
      "\n",
      "batch of two (multi-head) collections of query matrices (4D tensor) shape: (2, 2, 2, 3)\n",
      "\n",
      "[[[[1 0 0]\n",
      "   [0 1 0]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]]]\n",
      "\n",
      "\n",
      " [[[1 0 0]\n",
      "   [0 1 0]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]]]]\n",
      "\n",
      "one batch of concatenated heads of query matrices (3d tensor) shape: (1, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n",
      "three batches of concatenated heads of query matrices (3d tensor) shape: (3, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor2d = create_tensor(q)\n",
    "display_tensor(tensor2d, 'query matrix (2D tensor)')\n",
    "\n",
    "tensor4d2b = create_tensor([[q, q], [q, q]])\n",
    "display_tensor(tensor4d2b, 'batch of two (multi-head) collections of query matrices (4D tensor)')\n",
    "\n",
    "tensor3dc = create_tensor([jnp.concatenate([q, q], axis = -1)])\n",
    "display_tensor(tensor3dc, 'one batch of concatenated heads of query matrices (3d tensor)')\n",
    "\n",
    "tensor3dc3b = create_tensor([jnp.concatenate([q, q], axis = -1), jnp.concatenate([q, q], axis = -1), jnp.concatenate([q, q], axis = -1)])\n",
    "display_tensor(tensor3dc3b, 'three batches of concatenated heads of query matrices (3d tensor)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know that the following 3 functions would normally be defined within the `CausalAttention` function further below. \n",
    "\n",
    "However this makes these functions harder to test. Because of this, these functions are shown individually using a `closure` (when necessary) that simulates them being inside of the `CausalAttention` function. This is done because they rely on some variables that can be accessed from within `CausalAttention`.\n",
    "\n",
    "### Support Functions\n",
    "\n",
    "<a name='ex-2a'></a>\n",
    "### Exercise 2a - compute_attention_heads\n",
    "\n",
    "<span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (n_batch, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (n_batch $\\times$ n_heads, seqlen, d_head).\n",
    "\n",
    "**For the closures you only have to fill the inner function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: compute_attention_heads_closure\n",
    "def compute_attention_heads_closure(n_heads, d_head):\n",
    "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
    "    Args:\n",
    "        d_head (int):  dimensionality of heads\n",
    "        n_heads (int): number of attention heads\n",
    "    Returns:\n",
    "        function: compute_attention_heads function\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_attention_heads(x):\n",
    "        \"\"\" Compute the attention heads.\n",
    "        Args:\n",
    "            x (jax.interpreters.xla.DeviceArray): tensor with shape (n_batch, seqlen, n_heads X d_head).\n",
    "        Returns:\n",
    "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (n_batch X n_heads, seqlen, d_head).\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ###\n",
    "        # (REPLACE INSTANCES OF 'None' WITH YOUR CODE)\n",
    "        \n",
    "        # Size of the x's batch dimension\n",
    "        batch_size = x.shape[0]\n",
    "        # Length of the sequence\n",
    "        # Should be size of x's first dimension without counting the batch dim\n",
    "        seqlen = x.shape[1]\n",
    "        # Reshape x using jnp.reshape()\n",
    "        # n_batch, seqlen, n_heads*d_head -> n_batch, seqlen, n_heads, d_head\n",
    "        x = jnp.reshape(x, (batch_size, seqlen, n_heads, d_head))\n",
    "        # Transpose x using jnp.transpose()\n",
    "        # n_batch, seqlen, n_heads, d_head -> n_batch, n_heads, seqlen, d_head\n",
    "        # Note that the values within the tuple are the indexes of the dimensions of x and you must rearrange them\n",
    "        x = jnp.transpose(x, (0, 2, 1, 3))\n",
    "        # Reshape x using jnp.reshape()\n",
    "        # n_batch, n_heads, seqlen, d_head -> n_batch*n_heads, seqlen, d_head\n",
    "        x = jnp.reshape(x, (-1, seqlen, d_head))\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return x\n",
    "    return compute_attention_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor shape: (3, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n",
      "output tensor shape: (6, 2, 3)\n",
      "\n",
      "[[[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_tensor(tensor3dc3b, \"input tensor\")\n",
    "result_cah = compute_attention_heads_closure(2,3)(tensor3dc3b)\n",
    "display_tensor(result_cah, \"output tensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "input tensor shape: (3, 2, 6)\n",
    "\n",
    "[[[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]]\n",
    "\n",
    "output tensor shape: (6, 2, 3)\n",
    "\n",
    "[[[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "# test compute_attention_heads_closure\n",
    "w2_tests.test_compute_attention_heads_closure(compute_attention_heads_closure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-2b'></a>\n",
    "### Exercise 2b - dot_product_self_attention\n",
    "\n",
    "<span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: dot_product_self_attention\n",
    "def dot_product_self_attention(q, k, v):\n",
    "    \"\"\" Masked dot product self attention.\n",
    "    Args:\n",
    "        q (jax.interpreters.xla.DeviceArray): queries.\n",
    "        k (jax.interpreters.xla.DeviceArray): keys.\n",
    "        v (jax.interpreters.xla.DeviceArray): values.\n",
    "    Returns:\n",
    "        jax.interpreters.xla.DeviceArray: masked dot product self attention tensor.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # Hint: mask size should be equal to L_q. Remember that q has shape (batch_size, L_q, d)\n",
    "    mask_size = q.shape[1]\n",
    "\n",
    "\n",
    "    # Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)\n",
    "    # Notice that 1's and 0's get casted to True/False by setting dtype to jnp.bool_\n",
    "    # Use jnp.tril() - Lower triangle of an array and jnp.ones()\n",
    "    mask = jnp.tril(jnp.ones((1, mask_size, mask_size), dtype=jnp.bool_), k=0)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return DotProductAttention(q, k, v, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[0.        , 1.        , 0.        ],\n",
       "              [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product_self_attention(q_with_batch, k_with_batch, v_with_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "DeviceArray([[[0.        , 1.        , 0.        ],\n",
    "              [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "# test dot_product_self_attention\n",
    "w2_tests.test_dot_product_self_attention(dot_product_self_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-2c'></a>\n",
    "### Exercise 2c - compute_attention_output\n",
    "\n",
    "<span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (n_batch, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4\n",
    "# GRADED FUNCTION: compute_attention_output_closure\n",
    "def compute_attention_output_closure(n_heads, d_head):\n",
    "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
    "    Args:\n",
    "        d_head (int):  dimensionality of heads\n",
    "        n_heads (int): number of attention heads\n",
    "    Returns:\n",
    "        function: compute_attention_output function\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_attention_output(x):\n",
    "        \"\"\" Compute the attention output.\n",
    "        Args:\n",
    "            x (jax.interpreters.xla.DeviceArray): tensor with shape (n_batch X n_heads, seqlen, d_head).\n",
    "        Returns:\n",
    "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (n_batch, seqlen, n_heads X d_head).\n",
    "        \"\"\"\n",
    "        ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
    "        \n",
    "        # Length of the sequence\n",
    "        # Should be size of x's first dimension without counting the batch dim\n",
    "        seqlen = x.shape[1]\n",
    "        # Reshape x using jnp.reshape() to shape (n_batch, n_heads, seqlen, d_head)\n",
    "        # Use '-1' for `n_batch` in this case\n",
    "        x = jnp.reshape(x, (-1, n_heads, seqlen, d_head))\n",
    "        # Transpose x using jnp.transpose() to shape (n_batch, seqlen, n_heads, d_head)\n",
    "        x = jnp.transpose(x, (0, 2, 1, 3))\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Reshape to allow to concatenate the heads\n",
    "        return jnp.reshape(x, (-1, seqlen, n_heads * d_head))\n",
    "    return compute_attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor shape: (6, 2, 3)\n",
      "\n",
      "[[[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]]\n",
      "\n",
      "output tensor shape: (3, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_tensor(result_cah, \"input tensor\")\n",
    "result_cao = compute_attention_output_closure(2,3)(result_cah)\n",
    "display_tensor(result_cao, \"output tensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "input tensor shape: (6, 2, 3)\n",
    "\n",
    "[[[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]]\n",
    "\n",
    "output tensor shape: (3, 2, 6)\n",
    "\n",
    "[[[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "# test compute_attention_output_closure\n",
    "w2_tests.test_compute_attention_output_closure(compute_attention_output_closure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Attention Function\n",
    "\n",
    "Now it is time for you to put everything together within the `CausalAttention` or Masked multi-head attention function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/masked-attention.png\"> \n",
    "\n",
    "<a name='ex-2d'></a>\n",
    "### Exercise 2d - CausalAttention\n",
    "\n",
    "**Instructions:** Implement the causal attention.\n",
    "Your model returns the causal attention through a $tl.Serial$ with the following:\n",
    "\n",
    "- <span style='color:blue'> [tl.Branch](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Branch) </span>: consisting of 3 [tl.Dense(d_feature), ComputeAttentionHeads] to account for the queries, keys, and values.\n",
    "- <span style='color:blue'> [tl.Fn](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn)</span>: Takes in dot_product_self_attention function and uses it to compute the dot product using $Q$, $K$, $V$.\n",
    "- <span style='color:blue'> [tl.Fn](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn)</span>: Takes in compute_attention_output_closure to allow for parallel computing.\n",
    "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense)</span>: Final Dense layer, with dimension `d_feature`.\n",
    "\n",
    "Remember that in order for trax to properly handle the functions you just defined, they need to be added as layers using the [`tl.Fn()`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9Adn6DtRWRG"
   },
   "outputs": [],
   "source": [
    "# UNQ_C5\n",
    "# GRADED FUNCTION: CausalAttention\n",
    "def CausalAttention(d_feature, \n",
    "                    n_heads, \n",
    "                    compute_attention_heads_closure=compute_attention_heads_closure,\n",
    "                    dot_product_self_attention=dot_product_self_attention,\n",
    "                    compute_attention_output_closure=compute_attention_output_closure,\n",
    "                    mode='train'):\n",
    "    \"\"\"Transformer-style multi-headed causal attention.\n",
    "\n",
    "    Args:\n",
    "        d_feature (int):  dimensionality of feature embedding.\n",
    "        n_heads (int): number of attention heads.\n",
    "        compute_attention_heads_closure (function): Closure around compute_attention heads.\n",
    "        dot_product_self_attention (function): dot_product_self_attention function. \n",
    "        compute_attention_output_closure (function): Closure around compute_attention_output. \n",
    "        mode (str): 'train' or 'eval'.\n",
    "\n",
    "    Returns:\n",
    "        trax.layers.combinators.Serial: Multi-headed self-attention model.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert d_feature % n_heads == 0\n",
    "    d_head = d_feature // n_heads\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # (REPLACE INSTANCES OF 'None' WITH YOUR CODE)\n",
    "    \n",
    "    # HINT: The second argument to tl.Fn() is an uncalled function (without the parentheses)\n",
    "    # Since you are dealing with closures you might need to call the outer \n",
    "    # function with the correct parameters to get the actual uncalled function.\n",
    "    # use 'compute_attention_heads_closure'\n",
    "    ComputeAttentionHeads = tl.Fn('AttnHeads', compute_attention_heads_closure(n_heads, d_head), n_out=1)\n",
    "        \n",
    "\n",
    "    return tl.Serial(\n",
    "        tl.Branch( # creates three towers for one input, takes activations and creates queries keys and values\n",
    "            [tl.Dense(d_feature), ComputeAttentionHeads], # queries\n",
    "            [tl.Dense(d_feature), ComputeAttentionHeads], # keys\n",
    "            [tl.Dense(d_feature), ComputeAttentionHeads], # values\n",
    "        ),\n",
    "        \n",
    "        tl.Fn('DotProductAttn', dot_product_self_attention, n_out=1), # takes QKV\n",
    "        # HINT: The second argument to tl.Fn() is an uncalled function\n",
    "        # Since you are dealing with closures you might need to call the outer \n",
    "        # function with the correct parameters to get the actual uncalled function.\n",
    "        # 'compute_attention_output_closure'\n",
    "        tl.Fn('AttnOutput', compute_attention_output_closure(n_heads, d_head), n_out=1), # to allow for parallel\n",
    "        tl.Dense(d_feature)\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Branch_out3[\n",
      "    [Dense_512, AttnHeads]\n",
      "    [Dense_512, AttnHeads]\n",
      "    [Dense_512, AttnHeads]\n",
      "  ]\n",
      "  DotProductAttn_in3\n",
      "  AttnOutput\n",
      "  Dense_512\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the causal attention model\n",
    "print(CausalAttention(d_feature=512, n_heads=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "Serial[\n",
    "  Branch_out3[\n",
    "    [Dense_512, AttnHeads]\n",
    "    [Dense_512, AttnHeads]\n",
    "    [Dense_512, AttnHeads]\n",
    "  ]\n",
    "  DotProductAttn_in3\n",
    "  AttnOutput\n",
    "  Dense_512\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "# test CausalAttention\n",
    "w2_tests.test_CausalAttention(CausalAttention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6zwtPjqRWRJ"
   },
   "source": [
    "<a name='2-3'></a>\n",
    "### 2.3 - Transformer Decoder Block\n",
    "\n",
    "Now that you have implemented the causal part of the transformer, you will implement the transformer decoder block. Concretely you will be implementing this image now.\n",
    "\n",
    "<img src = \"images/transformer_decoder_1.png\" style = \"height:300px\"> \n",
    "\n",
    "To implement this function, you will have to call the `CausalAttention` or Masked multi-head attention function you implemented above. You will have to add a feedforward which consists of: \n",
    "\n",
    "- <span style='color:blue'> [tl.LayerNorm](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm) </span>: used to layer normalize\n",
    "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: the dense layer\n",
    "- <span style='color:blue'> [ff_activation](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.activation_fns.Relu) </span>: feed forward activation (we use ReLu) here.\n",
    "- <span style='color:blue'> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout) </span>: dropout layer\n",
    "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: dense layer\n",
    "- <span style='color:blue'> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout) </span>: dropout layer\n",
    "\n",
    "Finally once you implement the feedforward, you can go ahead and implement the entire block using: \n",
    "\n",
    "- <span style='color:blue'> [tl.Residual](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual) </span>: takes in the tl.LayerNorm(), causal attention block, tl.dropout. \n",
    "\n",
    "- <span style='color:blue'> [tl.Residual](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual) </span>: takes in the feedforward block you will implement. \n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Exercise 3 - DecoderBlock\n",
    "**Instructions:** Implement the transformer decoder block. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKOxnRbp1K5U"
   },
   "outputs": [],
   "source": [
    "# UNQ_C6\n",
    "# GRADED FUNCTION: DecoderBlock\n",
    "def DecoderBlock(d_model, d_ff, n_heads,\n",
    "                 dropout, mode, ff_activation):\n",
    "    \"\"\"Returns a list of layers that implements a Transformer decoder block.\n",
    "\n",
    "    The input is an activation tensor.\n",
    "\n",
    "    Args:\n",
    "        d_model (int):  depth of embedding.\n",
    "        d_ff (int): depth of feed-forward layer.\n",
    "        n_heads (int): number of attention heads.\n",
    "        dropout (float): dropout rate (how much to drop out).\n",
    "        mode (str): 'train' or 'eval'.\n",
    "        ff_activation (function): the non-linearity in feed-forward layer.\n",
    "\n",
    "    Returns:\n",
    "        list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
    "    \n",
    "    # Create masked multi-head attention block using CausalAttention function\n",
    "    causal_attention = CausalAttention( \n",
    "                        d_model,\n",
    "                        n_heads=n_heads,\n",
    "                        mode=mode\n",
    "                        )\n",
    "\n",
    "    # Create feed-forward block (list) with two dense layers with dropout and input normalized\n",
    "    feed_forward = [ \n",
    "        # Normalize layer inputs\n",
    "        tl.LayerNorm(),\n",
    "        # Add first feed forward (dense) layer (don't forget to set the correct value for n_units)\n",
    "        tl.Dense(d_ff),\n",
    "        # Add activation function passed in as a parameter (you need to call it!)\n",
    "        ff_activation(), # Generally ReLU\n",
    "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
    "        tl.Dropout(rate=dropout, mode=mode),\n",
    "        # Add second feed forward layer (don't forget to set the correct value for n_units)\n",
    "        tl.Dense(d_model),\n",
    "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
    "        tl.Dropout(rate=dropout, mode=mode)\n",
    "    ]\n",
    "\n",
    "    # Add list of two Residual blocks: the attention with normalization and dropout and feed-forward blocks\n",
    "    return [\n",
    "      tl.Residual(\n",
    "          # Normalize layer input\n",
    "          tl.LayerNorm(),\n",
    "          # Add causal attention block previously defined (without parentheses)\n",
    "          causal_attention,\n",
    "          # Add dropout with rate and mode specified\n",
    "          tl.Dropout(rate=dropout, mode=mode)\n",
    "        ),\n",
    "      tl.Residual(\n",
    "          # Add feed forward block (without parentheses)\n",
    "          feed_forward\n",
    "        ),\n",
    "      ]\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Serial[\n",
      "  Branch_out2[\n",
      "    None\n",
      "    Serial[\n",
      "      LayerNorm\n",
      "      Serial[\n",
      "        Branch_out3[\n",
      "          [Dense_512, AttnHeads]\n",
      "          [Dense_512, AttnHeads]\n",
      "          [Dense_512, AttnHeads]\n",
      "        ]\n",
      "        DotProductAttn_in3\n",
      "        AttnOutput\n",
      "        Dense_512\n",
      "      ]\n",
      "      Dropout\n",
      "    ]\n",
      "  ]\n",
      "  Add_in2\n",
      "], Serial[\n",
      "  Branch_out2[\n",
      "    None\n",
      "    Serial[\n",
      "      LayerNorm\n",
      "      Dense_2048\n",
      "      Serial[\n",
      "        Relu\n",
      "      ]\n",
      "      Dropout\n",
      "      Dense_512\n",
      "      Dropout\n",
      "    ]\n",
      "  ]\n",
      "  Add_in2\n",
      "]]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the decoder block\n",
    "print(DecoderBlock(d_model=512, d_ff=2048, n_heads=8, dropout=0.1, mode='train', ff_activation=tl.Relu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "[Serial[\n",
    "  Branch_out2[\n",
    "    None\n",
    "    Serial[\n",
    "      LayerNorm\n",
    "      Serial[\n",
    "        Branch_out3[\n",
    "          [Dense_512, AttnHeads]\n",
    "          [Dense_512, AttnHeads]\n",
    "          [Dense_512, AttnHeads]\n",
    "        ]\n",
    "        DotProductAttn_in3\n",
    "        AttnOutput\n",
    "        Dense_512\n",
    "      ]\n",
    "      Dropout\n",
    "    ]\n",
    "  ]\n",
    "  Add_in2\n",
    "], Serial[\n",
    "  Branch_out2[\n",
    "    None\n",
    "    Serial[\n",
    "      LayerNorm\n",
    "      Dense_2048\n",
    "      Serial[\n",
    "        Relu\n",
    "      ]\n",
    "      Dropout\n",
    "      Dense_512\n",
    "      Dropout\n",
    "    ]\n",
    "  ]\n",
    "  Add_in2\n",
    "]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "# test DecoderBlock\n",
    "w2_tests.test_DecoderBlock(DecoderBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoFv-nfLRWRN",
    "lines_to_next_cell": 0
   },
   "source": [
    "<a name='2-4'></a>\n",
    "### 2.4 - Transformer Language Model\n",
    "\n",
    "You will now bring it all together. In this part you will use all the subcomponents you previously built to make the final model. Concretely, here is the image you will be implementing. \n",
    "<img src = \"images/transformer_decoder.png\" style = \"height:400px\">\n",
    "\n",
    "    \n",
    "<a name='ex-4'></a>\n",
    "### Exercise 4 - TransformerLM\n",
    "**Instructions:** Previously you coded the decoder block. Now you will code the transformer language model. Here is what you will need. \n",
    "\n",
    "- <span style=\"color:blue\"> positional_enconder </span>- a list containing the following layers:\n",
    "    - <span style=\"color:blue\"> [tl.Embedding](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding)\n",
    "    - <span style=\"color:blue\"> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout)\n",
    "    - <span style=\"color:blue\"> [tl.PositionalEncoding](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.PositionalEncoding)\n",
    "\n",
    "- A list of `n_layers` <span style=\"color:blue\"> decoder blocks</span>.\n",
    "- <span style=\"color:blue\"> [tl.Serial](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial): </span> takes in the following layers or lists of layers:\n",
    "    - <span style=\"color:blue\"> [tl.ShiftRight](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.ShiftRight): </span>: shift the tensor to the right by padding on axis 1.\n",
    "    - <span style=\"color:blue\"> positional_encoder </span>: encodes the text positions.\n",
    "    - <span style=\"color:blue\"> decoder_blocks </span>: the ones you created.\n",
    "    - <span style=\"color:blue\"> [tl.LayerNorm](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm) </span>: a layer norm.\n",
    "    - <span style=\"color:blue\"> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: takes in the vocab_size.\n",
    "    - <span style=\"color:blue\"> [tl.LogSoftmax](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax) </span>: to predict.\n",
    "    \n",
    "Go go go!! You can do it :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0yi4LJO1RWRS"
   },
   "outputs": [],
   "source": [
    "# UNQ_C7\n",
    "# GRADED FUNCTION: TransformerLM\n",
    "def TransformerLM(vocab_size=33300,\n",
    "                  d_model=512,\n",
    "                  d_ff=2048,\n",
    "                  n_layers=6,\n",
    "                  n_heads=8,\n",
    "                  dropout=0.1,\n",
    "                  max_len=4096,\n",
    "                  mode='train',\n",
    "                  ff_activation=tl.Relu):\n",
    "    \"\"\"Returns a Transformer language model.\n",
    "\n",
    "    The input to the model is a tensor of tokens. (This model uses only the\n",
    "    decoder part of the overall Transformer.)\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): vocab size.\n",
    "        d_model (int):  depth of embedding.\n",
    "        d_ff (int): depth of feed-forward layer.\n",
    "        n_layers (int): number of decoder layers.\n",
    "        n_heads (int): number of attention heads.\n",
    "        dropout (float): dropout rate (how much to drop out).\n",
    "        max_len (int): maximum symbol length for positional encoding.\n",
    "        mode (str): 'train', 'eval' or 'predict', predict mode is for fast inference.\n",
    "        ff_activation (function): the non-linearity in feed-forward layer.\n",
    "\n",
    "    Returns:\n",
    "        trax.layers.combinators.Serial: A Transformer language model as a layer that maps from a tensor of tokens\n",
    "        to activations over a vocab set.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
    "    \n",
    "    # Embedding inputs and positional encoder\n",
    "    positional_encoder = [ \n",
    "        # Add embedding layer of dimension (vocab_size, d_model)\n",
    "        tl.Embedding(vocab_size, d_model),\n",
    "        # Use dropout with rate and mode specified\n",
    "        tl.Dropout(rate=dropout, mode=mode),\n",
    "        # Add positional encoding layer with maximum input length and mode specified\n",
    "        tl.PositionalEncoding(max_len=max_len, mode=mode)]\n",
    "\n",
    "    # Create stack (list) of decoder blocks with n_layers with necessary parameters\n",
    "    decoder_blocks = [ \n",
    "        DecoderBlock(d_model, d_ff, n_heads, dropout, mode, ff_activation) for _ in range(n_layers)]\n",
    "\n",
    "    # Create the complete model as written in the figure\n",
    "    return tl.Serial(\n",
    "        # Use teacher forcing (feed output of previous step to current step)\n",
    "        tl.ShiftRight(mode=mode), # Specify the mode!\n",
    "        # Add positional encoder\n",
    "        positional_encoder,\n",
    "        # Add decoder blocks\n",
    "        decoder_blocks,\n",
    "        # Normalize layer\n",
    "        tl.LayerNorm(),\n",
    "\n",
    "        # Add dense layer of vocab_size (since need to select a word to translate to)\n",
    "        # (a.k.a., logits layer. Note: activation already set by ff_activation)\n",
    "        tl.Dense(vocab_size),\n",
    "        # Get probabilities with Logsoftmax\n",
    "        tl.LogSoftmax()\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Serial[\n",
      "    ShiftRight(1)\n",
      "  ]\n",
      "  Embedding_33300_512\n",
      "  Dropout\n",
      "  PositionalEncoding\n",
      "  Serial[\n",
      "    Branch_out2[\n",
      "      None\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "        Serial[\n",
      "          Branch_out3[\n",
      "            [Dense_512, AttnHeads]\n",
      "            [Dense_512, AttnHeads]\n",
      "            [Dense_512, AttnHeads]\n",
      "          ]\n",
      "          DotProductAttn_in3\n",
      "          AttnOutput\n",
      "          Dense_512\n",
      "        ]\n",
      "        Dropout\n",
      "      ]\n",
      "    ]\n",
      "    Add_in2\n",
      "  ]\n",
      "  Serial[\n",
      "    Branch_out2[\n",
      "      None\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "        Dense_2048\n",
      "        Serial[\n",
      "          Relu\n",
      "        ]\n",
      "        Dropout\n",
      "        Dense_512\n",
      "        Dropout\n",
      "      ]\n",
      "    ]\n",
      "    Add_in2\n",
      "  ]\n",
      "  LayerNorm\n",
      "  Dense_33300\n",
      "  LogSoftmax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the Transformer\n",
    "print(TransformerLM(n_layers=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "Serial[\n",
    "  Serial[\n",
    "    ShiftRight(1)\n",
    "  ]\n",
    "  Embedding_33300_512\n",
    "  Dropout\n",
    "  PositionalEncoding\n",
    "  Serial[\n",
    "    Branch_out2[\n",
    "      None\n",
    "      Serial[\n",
    "        LayerNorm\n",
    "        Serial[\n",
    "          Branch_out3[\n",
    "            [Dense_512, AttnHeads]\n",
    "            [Dense_512, AttnHeads]\n",
    "            [Dense_512, AttnHeads]\n",
    "          ]\n",
    "          DotProductAttn_in3\n",
    "          AttnOutput\n",
    "          Dense_512\n",
    "        ]\n",
    "        Dropout\n",
    "      ]\n",
    "    ]\n",
    "    Add_in2\n",
    "  ]\n",
    "  Serial[\n",
    "    Branch_out2[\n",
    "      None\n",
    "      Serial[\n",
    "        LayerNorm\n",
    "        Dense_2048\n",
    "        Serial[\n",
    "          Relu\n",
    "        ]\n",
    "        Dropout\n",
    "        Dense_512\n",
    "        Dropout\n",
    "      ]\n",
    "    ]\n",
    "    Add_in2\n",
    "  ]\n",
    "  LayerNorm\n",
    "  Dense_33300\n",
    "  LogSoftmax\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "# test TransformerLM\n",
    "w2_tests.test_TransformerLM(TransformerLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRRKnoAdvmJ7"
   },
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Training\n",
    "\n",
    "Now you are going to train your model. As usual, you have to define the cost function, the optimizer, and decide whether you will be training it on a `gpu` or `cpu`. In this case, you will train your model on a cpu for a few steps and we will load in a pre-trained model that you can use to predict with your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1lkVebQRWRV"
   },
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 - Training the Model\n",
    "\n",
    "You will now write a function that takes in your model and trains it. To train your model you have to decide how many times you want to iterate over the entire data set. Each iteration is defined as an `epoch`. For each epoch, you have to go over all the data, using your training iterator.\n",
    "\n",
    "<a name='ex-5'></a>\n",
    "### Exercise 5 - training_loop\n",
    "**Instructions:** Implement the `train_model` program below to train the neural network above. Here is a list of things you should do:\n",
    "\n",
    "- Create the train task by calling [`trax.supervised.training.TrainTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask) and pass in the following: \n",
    "    - <span style='color:blue'> labeled_data </span> = train_gen\n",
    "    - <span style='color:blue'> loss_layer </span> = [tl.CrossEntropyLoss()](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.CrossEntropyLoss)\n",
    "    - <span style='color:blue'> optimizer </span> = [trax.optimizers.Adam(0.01)](https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html#trax.optimizers.adam.Adam)\n",
    "    - <span style='color:blue'> lr_schedule </span> = [lr_schedule](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.lr_schedules.warmup_and_rsqrt_decay)\n",
    "\n",
    "\n",
    "- Create the eval task by calling [`trax.supervised.training.EvalTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask) and pass in the following: \n",
    "    - <span style='color:blue'> labeled_data </span> = eval_gen\n",
    "    - <span style='color:blue'> metrics </span> = tl.CrossEntropyLoss() and [tl.Accuracy()](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.Accuracy)\n",
    "    \n",
    "    \n",
    "- Create the training loop by calling [`trax.supervised.Training.Loop`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop) and pass in the following: \n",
    "    - <span style='color:blue'> TransformerLM </span> \n",
    "    - <span style='color:blue'> train_task </span> \n",
    "    - <span style='color:blue'> eval_tasks </span> = [eval_task]\n",
    "    - <span style='color:blue'> output_dir</span> = output_dir\n",
    "    \n",
    "You will be using a cross entropy loss, with Adam optimizer. Please read the [Trax](https://trax-ml.readthedocs.io/en/latest/index.html) documentation to get a full understanding. \n",
    "\n",
    "The training loop that this function returns can be runned using the `run()` method by passing in the desired number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gM2gpu4xvjtX"
   },
   "outputs": [],
   "source": [
    "### DO NOT REMOVE THE BELOW LINE OF CODE\n",
    "from trax.supervised import training\n",
    "\n",
    "# UNQ_C8\n",
    "# GRADED FUNCTION: train_model\n",
    "def training_loop(TransformerLM, train_gen, eval_gen, output_dir = \"~/model\"):\n",
    "    '''\n",
    "    Input:\n",
    "        TransformerLM (trax.layers.combinators.Serial): The model you are building.\n",
    "        train_gen (generator): Training stream of data.\n",
    "        eval_gen (generator): Evaluation stream of data.\n",
    "        output_dir (str): folder to save your file.\n",
    "        \n",
    "    Returns:\n",
    "        trax.supervised.training.Loop: Training loop.\n",
    "    '''\n",
    "    output_dir = os.path.expanduser(output_dir)  # trainer is an object\n",
    "    lr_schedule = trax.lr.warmup_and_rsqrt_decay(n_warmup_steps=1000, max_value=0.01)\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
    "    train_task = training.TrainTask( \n",
    "      labeled_data=train_gen, # The training generator\n",
    "      loss_layer=tl.CrossEntropyLoss(), # Loss function (Don't forget to instantiate!)\n",
    "      optimizer=trax.optimizers.Adam(0.01), # Optimizer (Don't forget to set LR to 0.01)\n",
    "      lr_schedule=lr_schedule,\n",
    "      n_steps_per_checkpoint=10 \n",
    "    )\n",
    "\n",
    "    eval_task = training.EvalTask( \n",
    "      labeled_data=eval_gen, # The evaluation generator\n",
    "      metrics=[tl.CrossEntropyLoss(), tl.Accuracy()] # CrossEntropyLoss and Accuracy (Don't forget to instantiate both!)\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    loop = training.Loop(TransformerLM(d_model=4,\n",
    "                                       d_ff=16,\n",
    "                                       n_layers=1,\n",
    "                                       n_heads=2,\n",
    "                                       mode='train'),\n",
    "                         train_task,\n",
    "                         eval_tasks=[eval_task],\n",
    "                         output_dir=output_dir)\n",
    "    \n",
    "    return loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model will be trained for only 10 steps. \n",
    "\n",
    "Even with this constraint the model with the original default arguments took a very long time to finish. Because of this some parameters are changed when defining the model that is fed into the training loop in the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "# test training_loop\n",
    "w2_tests.test_training_loop(training_loop, TransformerLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "BFRBTwSqRWRZ",
    "outputId": "aff859e5-8f4a-4d3b-f1d3-98e137581a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 316336\n",
      "Step      1: Ran 1 train steps in 10.51 secs\n",
      "Step      1: train CrossEntropyLoss |  10.41195965\n",
      "Step      1: eval  CrossEntropyLoss |  10.41570950\n",
      "Step      1: eval          Accuracy |  0.00000000\n",
      "\n",
      "Step     10: Ran 9 train steps in 93.66 secs\n",
      "Step     10: train CrossEntropyLoss |  10.41409397\n",
      "Step     10: eval  CrossEntropyLoss |  10.41572475\n",
      "Step     10: eval          Accuracy |  0.00000000\n"
     ]
    }
   ],
   "source": [
    "# Should take around 1.5 minutes\n",
    "!rm -f ~/model/model.pkl.gz\n",
    "loop = training_loop(TransformerLM, train_batch_stream, eval_batch_stream)\n",
    "loop.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKrEBjmskeWa"
   },
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Evaluation  \n",
    "\n",
    "<a name='4-1'></a>\n",
    "### 4.1 - Loading in a Trained Model\n",
    "\n",
    "In this part you will evaluate by loading in an almost exact version of the model you coded, but we trained it for you to save you time. Please run the cell below to load in the model.\n",
    "\n",
    "As you may have already noticed the model that you trained and the pretrained model share the same overall architecture but they have different values for some of the parameters:\n",
    "\n",
    "    \n",
    "   `Original (pretrained) model: `                                 \n",
    "                                       \n",
    "    TransformerLM(vocab_size=33300, d_model=512, d_ff=2048, n_layers=6, n_heads=8, \n",
    "                   dropout=0.1, max_len=4096, ff_activation=tl.Relu)\n",
    "                   \n",
    "   `Your model:`\n",
    "   \n",
    "    TransformerLM(d_model=4, d_ff=16, n_layers=1, n_heads=2)\n",
    "   \n",
    "   **Only the parameters shown for your model were changed. The others stayed the same.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS STEP COULD TAKE BETWEEN 15 SECONDS TO 15 MINUTES\n",
    "# Get the model architecture\n",
    "model = TransformerLM(mode='eval')\n",
    "\n",
    "# Load the pre-trained weights\n",
    "model.init_from_file('model.pkl.gz', weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilM9C8P3RWRf"
   },
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Testing with your Own Input\n",
    "\n",
    "You will now test your input. You are going to implement greedy decoding. This consists of two functions. The first one allows you to identify the next symbol. It gets the argmax of the output of your model and then returns that index. \n",
    "\n",
    "<a name='ex-6'></a>\n",
    "### Exercise 6 - next_symbol\n",
    "**Instructions:** Implement the next symbol function that takes in the cur_output_tokens and the trained model to return the the index of the next word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rD_bXRCpRWRg"
   },
   "outputs": [],
   "source": [
    "# UNQ_C9\n",
    "def next_symbol(cur_output_tokens, model):\n",
    "    \"\"\"Returns the next symbol for a given sentence.\n",
    "\n",
    "    Args:\n",
    "        cur_output_tokens (list): tokenized sentence with EOS and PAD tokens at the end.\n",
    "        model (trax.layers.combinators.Serial): The transformer model.\n",
    "\n",
    "    Returns:\n",
    "        int: tokenized symbol.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
    "    \n",
    "    # current output tokens length\n",
    "    token_length = len(cur_output_tokens)\n",
    "    # calculate the minimum power of 2 big enough to store token_length\n",
    "    # HINT: use np.ceil() and np.log2()\n",
    "    # add 1 to token_length so np.log2() doesn't receive 0 when token_length is 0\n",
    "    padded_length = 2**int(np.ceil(np.log2(token_length + 1)))\n",
    "\n",
    "    # Fill cur_output_tokens with 0's until it reaches padded_length\n",
    "    padded = cur_output_tokens + [0] * (padded_length - token_length)\n",
    "    padded_with_batch = np.array(padded)[None, :] # Don't replace this None! This is a way of setting the batch dim\n",
    "\n",
    "    # model expects a tuple containing two padded tensors (with batch)\n",
    "    output, _ = model((padded_with_batch, padded_with_batch)) \n",
    "    # HINT: output has shape (1, padded_length, vocab_size)\n",
    "    # To get log_probs you need to index output wih 0 in the first dim\n",
    "    # token_length in the second dim and all of the entries for the last dim.\n",
    "    log_probs = output[0, token_length, :]\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return int(np.argmax(log_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it out!\n",
    "sentence_test_nxt_symbl = \"I want to fly in the sky.\"\n",
    "detokenize([next_symbol(tokenize(sentence_test_nxt_symbl)+[0], model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "'The'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "# test next_symbol\n",
    "w2_tests.test_next_symbol(next_symbol, TransformerLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AwrQFglRWRj"
   },
   "source": [
    "<a name='5-1'></a>\n",
    "### 5.1 - Greedy Decoding\n",
    "\n",
    "Now you will implement the greedy_decode algorithm that will call the `next_symbol` function. It takes in the input_sentence, the trained model and returns the the decoded sentence. \n",
    "\n",
    "<a name='ex-7'></a>\n",
    "### Exercise 7 - greedy_decode\n",
    "\n",
    "**Instructions**: Implement the greedy_decode algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HwIdimiN0k2"
   },
   "outputs": [],
   "source": [
    "# UNQ_C10\n",
    "# Decoding functions.\n",
    "def greedy_decode(input_sentence, model, next_symbol=next_symbol, tokenize=tokenize, detokenize=detokenize):\n",
    "    \"\"\"Greedy decode function.\n",
    "\n",
    "    Args:\n",
    "        input_sentence (string): a sentence or article.\n",
    "        model (trax.layers.combinators.Serial): Transformer model.\n",
    "\n",
    "    Returns:\n",
    "        string: summary of the input.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
    "    # Use tokenize()\n",
    "    cur_output_tokens = tokenize(input_sentence) + [0]    \n",
    "    generated_output = [] \n",
    "    cur_output = 0 \n",
    "    EOS = 1 \n",
    "    \n",
    "    while cur_output != EOS:\n",
    "        # Get next symbol\n",
    "        cur_output = next_symbol(cur_output_tokens, model)\n",
    "        # Append next symbol to original sentence\n",
    "        cur_output_tokens.append(cur_output)\n",
    "        # Append next symbol to generated sentence\n",
    "        generated_output.append(cur_output)\n",
    "        \n",
    "        print(detokenize(generated_output))\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "    return detokenize(generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "9kHuIDGW1sOr",
    "outputId": "2525ca2c-4625-47c0-8456-f75598581993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a sunny day when I went to the market to buy some flowers. But\n",
      "I only found roses, not tulips. \n",
      "\n",
      ":\n",
      ": I\n",
      ": I just\n",
      ": I just found\n",
      ": I just found ros\n",
      ": I just found roses\n",
      ": I just found roses,\n",
      ": I just found roses, not\n",
      ": I just found roses, not tu\n",
      ": I just found roses, not tulips\n",
      ": I just found roses, not tulips\n",
      ": I just found roses, not tulips.\n",
      ": I just found roses, not tulips.<EOS>\n",
      ": I just found roses, not tulips.<EOS>\n"
     ]
    }
   ],
   "source": [
    "# Test it out on a sentence!\n",
    "test_sentence = \"It was a sunny day when I went to the market to buy some flowers. But I only found roses, not tulips.\"\n",
    "print(wrapper.fill(test_sentence), '\\n')\n",
    "print(greedy_decode(test_sentence, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CA-279WI2D3G"
   },
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    ":\n",
    ": I\n",
    ": I just\n",
    ": I just found\n",
    ": I just found ros\n",
    ": I just found roses\n",
    ": I just found roses,\n",
    ": I just found roses, not\n",
    ": I just found roses, not tu\n",
    ": I just found roses, not tulips\n",
    ": I just found roses, not tulips\n",
    ": I just found roses, not tulips.\n",
    ": I just found roses, not tulips.<EOS>\n",
    ": I just found roses, not tulips.<EOS>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DYgX-mzjyUia",
    "outputId": "b901e164-48b3-4124-d21a-fe7443d15b79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It’s the posing craze sweeping the U.S. after being brought to fame by\n",
      "skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert\n",
      "Pujols - and even Republican politician Rick Perry. But now four\n",
      "students at Riverhead High School on Long Island, New York, have been\n",
      "suspended for dropping to a knee and taking up a prayer pose to mimic\n",
      "Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel,\n",
      "Tyler Carroll and Connor Carroll were all suspended for one day\n",
      "because the ‘Tebowing’ craze was blocking the hallway and presenting a\n",
      "safety hazard to students. Scroll down for video. Banned: Jordan\n",
      "Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured\n",
      "left) were all suspended for one day by Riverhead High School on Long\n",
      "Island, New York, for their tribute to Broncos quarterback Tim Tebow.\n",
      "Issue: Four of the pupils were suspended for one day because they\n",
      "allegedly did not heed to warnings that the 'Tebowing' craze at the\n",
      "school was blocking the hallway and presenting a safety hazard to\n",
      "students. \n",
      "\n",
      "Jordan\n",
      "Jordan Ful\n",
      "Jordan Fulcol\n",
      "Jordan Fulcoly\n",
      "Jordan Fulcoly,\n",
      "Jordan Fulcoly, Wayne\n",
      "Jordan Fulcoly, Wayne Dre\n",
      "Jordan Fulcoly, Wayne Drexe\n",
      "Jordan Fulcoly, Wayne Drexel\n",
      "Jordan Fulcoly, Wayne Drexel,\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day.\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not hee\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warn\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the '\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Te\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebow\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "cra\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocki\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hall\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety hazard\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety hazard to\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety hazard to\n",
      "students\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety hazard to\n",
      "students.\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety hazard to\n",
      "students.<EOS>\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety hazard to\n",
      "students.<EOS>\n"
     ]
    }
   ],
   "source": [
    "# Test it out with a whole article!\n",
    "article = \"It’s the posing craze sweeping the U.S. after being brought to fame by skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert Pujols - and even Republican politician Rick Perry. But now four students at Riverhead High School on Long Island, New York, have been suspended for dropping to a knee and taking up a prayer pose to mimic Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were all suspended for one day because the ‘Tebowing’ craze was blocking the hallway and presenting a safety hazard to students. Scroll down for video. Banned: Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured left) were all suspended for one day by Riverhead High School on Long Island, New York, for their tribute to Broncos quarterback Tim Tebow. Issue: Four of the pupils were suspended for one day because they allegedly did not heed to warnings that the 'Tebowing' craze at the school was blocking the hallway and presenting a safety hazard to students.\"\n",
    "print(wrapper.fill(article), '\\n')\n",
    "print(greedy_decode(article, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "Jordan\n",
    "Jordan Ful\n",
    "Jordan Fulcol\n",
    "Jordan Fulcoly\n",
    "Jordan Fulcoly,\n",
    "Jordan Fulcoly, Wayne\n",
    "Jordan Fulcoly, Wayne Dre\n",
    "Jordan Fulcoly, Wayne Drexe\n",
    "Jordan Fulcoly, Wayne Drexel\n",
    "Jordan Fulcoly, Wayne Drexel,\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "Final summary:\n",
    "\n",
    "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
    "suspended for one day. Four students were suspended for one day\n",
    "because they allegedly did not heed to warnings that the 'Tebowing'\n",
    "craze was blocking the hallway and presenting a safety hazard to\n",
    "students.<EOS>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      ": I\n",
      ": I just\n",
      ": I just found\n",
      ": I just found ros\n",
      ": I just found roses\n",
      ": I just found roses,\n",
      ": I just found roses, not\n",
      ": I just found roses, not tu\n",
      ": I just found roses, not tulips\n",
      ": I just found roses, not tulips\n",
      ": I just found roses, not tulips.\n",
      ": I just found roses, not tulips.<EOS>\n",
      "Jordan\n",
      "Jordan Ful\n",
      "Jordan Fulcol\n",
      "Jordan Fulcoly\n",
      "Jordan Fulcoly,\n",
      "Jordan Fulcoly, Wayne\n",
      "Jordan Fulcoly, Wayne Dre\n",
      "Jordan Fulcoly, Wayne Drexe\n",
      "Jordan Fulcoly, Wayne Drexel\n",
      "Jordan Fulcoly, Wayne Drexel,\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day.\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not hee\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warn\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the '\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Te\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebow\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "cra\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocki\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hall\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety hazard\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety hazard to\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety hazard to\n",
      "students\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety hazard to\n",
      "students.\n",
      "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
      "suspended for one day. Four students were suspended for one day\n",
      "because they allegedly did not heed to warnings that the 'Tebowing'\n",
      "craze was blocking the hallway and presenting a safety hazard to\n",
      "students.<EOS>\n",
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "# test greedy_decode\n",
    "w2_tests.test_greedy_decode(greedy_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on finishing this week's assignment!** You did a lot of work and now you should have a better understanding of the enconder part of Transformers and how Transformers can be used for text summarization.\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
